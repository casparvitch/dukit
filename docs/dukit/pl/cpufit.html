<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.9.2" />
<title>dukit.pl.cpufit API documentation</title>
<meta name="description" content="This module holds tools for fitting raw data via scipy. (scipy backend) â€¦" />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}#lunr-search{width:100%;font-size:1em;padding:6px 9px 5px 9px;border:1px solid silver}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS_CHTML" integrity="sha256-kZafAc6mZvK3W3v1pHOcUix30OHQN6pU/NO2oFkqZVw=" crossorigin></script>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>dukit.pl.cpufit</code></h1>
</header>
<section id="section-intro">
<p>This module holds tools for fitting raw data via scipy. (scipy backend)</p>
<h2 id="functions">Functions</h2>
<ul>
<li><code><a title="dukit.pl.cpufit.fit_roi_avg_pl" href="#dukit.pl.cpufit.fit_roi_avg_pl">fit_roi_avg_pl()</a></code></li>
<li><code><a title="dukit.pl.cpufit.fit_aois_pl" href="#dukit.pl.cpufit.fit_aois_pl">fit_aois_pl()</a></code></li>
<li><code>qdmpy.pl.cpufit.fit_all_pixels_pl</code></li>
<li><code><a title="dukit.pl.cpufit._gen_cf_guesses_bounds" href="#dukit.pl.cpufit._gen_cf_guesses_bounds">_gen_cf_guesses_bounds()</a></code></li>
</ul>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python"># -*- coding: utf-8 -*-
&#34;&#34;&#34;
This module holds tools for fitting raw data via scipy. (scipy backend)

Functions
---------
 - `dukit.pl.cpufit.fit_roi_avg_pl`
 - `dukit.pl.cpufit.fit_aois_pl`
 - `qdmpy.pl.cpufit.fit_all_pixels_pl`
 - `dukit.pl.cpufit._gen_cf_guesses_bounds`
&#34;&#34;&#34;

# ============================================================================

__author__ = &#34;Sam Scholten&#34;
__pdoc__ = {
    &#34;dukit.pl.cpufit.fit_roi_avg_pl&#34;: True,
    &#34;dukit.pl.cpufit.fit_aois_pl&#34;: True,
    &#34;dukit.pl.cpufit.fit_all_pixels_pl&#34;: True,
    &#34;dukit.pl.cpufit._gen_cf_guesses_bounds&#34;: True,
}

# ==========================================================================

import numpy as np
import numpy.typing as npt
import logging

import pycpufit.cpufit as cf

# ============================================================================

import dukit.pl.common
import dukit.warn
import dukit.share
import dukit.itool
import dukit.pl.model


# ==========================================================================


def _get_cpufit_modelID(fit_model: &#34;dukit.pl.model.FitModel&#34;):
    &#34;&#34;&#34;
    Get cpufit modelID from fit_model.

    Parameters
    ----------
    fit_model : dukit.pl.model.FitModel

    Returns
    -------
    cf.ModelID object
    &#34;&#34;&#34;
    err = cf.get_last_error()
    if err:
        dukit.warn.warn(f&#34;Cpufit error check:\n{err}&#34;)
    if isinstance(fit_model, dukit.pl.model.ConstStretchedExp):
        return cf.ModelID.STRETCHED_EXP
    if isinstance(fit_model, dukit.pl.model.ConstDampedRabi):
        return cf.ModelID.DAMPED_RABI
    if isinstance(fit_model, dukit.pl.model.LinearLorentzians):
        return cf.ModelID.LORENTZ8_LINEAR
    if isinstance(fit_model, dukit.pl.model.ConstLorentzians):
        return cf.ModelID.LORENTZ8_CONST
    raise RuntimeError(&#34;Model not recognised&#34;)


def fit_roi_avg_pl(
    sig: npt.NDArray,
    ref: npt.NDArray,
    sweep_arr: npt.NDArray,
    fit_model: &#34;dukit.pl.model.FitModel&#34;,
    guess_dict: dict,
    bounds_dict: dict,
    norm: str = &#34;div&#34;,
    estimator_id: str = &#34;LSE&#34;,
    tolerance: float = 1e-12,
    max_iterations: int = 50,
):
    &#34;&#34;&#34;
    Fit AOI averages

    Arguments
    ---------
    sig : np array, 3D
        Sig measurement array, shape: [y, x, sweep_arr]. CROPPED etc. already.
    ref : np array, 3D
        Ref measurement array, shape: [y, x, sweep_arr]. CROPPED etc. already.
    sweep_arr : np array, 1D
        Affine parameter list (e.g. tau or freq)
    fit_model : dukit.pl.model.FitModel
        The model we&#39;re fitting to.
    guess_dict : dict
        dict holding guesses for each parameter type, e.g.
        {&#39;pos&#39;: [.., ..], &#39;amp&#39;: [.., ..], ...}
    bounds_dict : dict
        dict holding bound options for each parameter type, e.g.
        {&#34;pos_range&#34;: 5.0, &#34;amp_bounds&#34;: [0.0, 1.0], ...}
    norm : str default=&#34;div&#34;
        Normalisation method

    Optional parameters passed to cpufit
    ------------------------------------
    tolerance : float = 1e-12
        Fit tolerance threshold
    max_iterations : int = 50
        Maximum fit iterations permitted.
    estimator_id : str = &#34;LSE&#34;
        Estimator to use, &#34;LSE&#34; or &#34;MLE&#34; (least squares or maximum likelihood).
        MLE for Poisson, assuming all noise in data is purely Poissonian.

    Returns
    -------
    fit_image_results : dukit.share.RoiAvgFit
    &#34;&#34;&#34;
    pguess, pbounds = _gen_cf_guesses_bounds(
        fit_model, *dukit.pl.common.gen_init_guesses(fit_model, guess_dict, bounds_dict)
    )

    if norm == &#34;div&#34;:
        sig_norm = sig / ref
    elif norm == &#34;sub&#34;:
        sig_norm = 1 + (sig - ref) / (sig + ref)
    elif norm == &#34;true_sub&#34;:
        sig_norm = (sig - ref) / np.nanmax(sig - ref).reshape(
                sig.shape[:-1] + (1,)
            ),

    avg_sig_norm = np.nanmean(sig_norm, axis=(0, 1))
    avg_sig = np.nanmean(sig, axis=(0, 1))
    avg_ref = np.nanmean(ref, axis=(0, 1))

    # only fit the params we want to :)
    params_to_fit = _get_params_to_fit(fit_model)

    # need to repeat avg_sig_norm twice, as cpufit expects 2D array
    roi_norm_twice = np.repeat([avg_sig_norm], repeats=2, axis=0).astype(np.float32)
    guess = np.repeat([pguess], repeats=2, axis=0).astype(dtype=np.float32)
    constraints = np.repeat([pbounds], repeats=2, axis=0).astype(dtype=np.float32)
    constraint_types = np.array(
        [cf.ConstraintType.LOWER_UPPER for i in range(len(params_to_fit))]
    ).astype(np.int32)

    model_id = _get_cpufit_modelID(fit_model)

    estimator_id = {&#34;LSE&#34;: cf.EstimatorID.LSE, &#34;MLE&#34;: cf.EstimatorID.MLE}.get(
        estimator_id, cf.EstimatorID.LSE
    )

    best_params_cf, _, _, _, _ = cf.fit_constrained(
        roi_norm_twice,
        None,
        model_id,
        guess,
        constraints=constraints,
        constraint_types=constraint_types,
        user_info=sweep_arr.astype(dtype=np.float32),
        parameters_to_fit=params_to_fit,
        estimator_id=estimator_id,
        tolerance=tolerance,
        max_number_iterations=max_iterations,
    )

    best_params = best_params_cf[0, :]  # just take first fit

    # manually compute sigmas, using analytic jacobian etc.
    best_sigmas = dukit.pl.common.calc_sigmas(
        fit_model, sweep_arr, avg_sig_norm, best_params
    )
    best_residual = fit_model(best_params, sweep_arr) - avg_sig_norm

    fit_xvec = np.linspace(
        np.min(sweep_arr),
        np.max(sweep_arr),
        10000,
    )
    fit_yvec = fit_model(best_params, fit_xvec)
    fit_yvec_guess = fit_model(pguess, fit_xvec)
    return dukit.share.RoiAvgFit(
        &#34;cpufit&#34;,
        sweep_arr,
        avg_sig_norm,
        avg_sig,
        avg_ref,
        fit_xvec,
        fit_yvec,
        fit_yvec_guess,
        best_params,
        best_sigmas,
        best_residual,
        pguess,
        pbounds,
    )


# ==========================================================================


def fit_aois_pl(
    sig: npt.NDArray,
    ref: npt.NDArray,
    sweep_arr: npt.NDArray,
    fit_model: &#34;dukit.pl.model.FitModel&#34;,
    guess_dict: dict,
    bounds_dict: dict,
    *aoi_coords: tuple[int, int, int, int],
    norm: str = &#34;div&#34;,
    estimator_id: str = &#34;LSE&#34;,
    tolerance: float = 1e-12,
    max_iterations: int = 50,
) -&gt; dict[str, dict[str, dukit.share.AoiAvgFit]]:
    &#34;&#34;&#34;
    Fit AOI averages

    Arguments
    ---------
    sig : np array, 3D
        Sig measurement array, shape: [y, x, sweep_arr].
    ref : np array, 3D
        Ref measurement array, shape: [y, x, sweep_arr].
    sweep_arr : np array, 1D
        Affine parameter list (e.g. tau or freq)
    fit_model : dukit.pl.model.FitModel
        The model we&#39;re fitting to.
    guess_dict : dict
        dict holding guesses for each parameter type, e.g.
        {&#39;pos&#39;: [.., ..], &#39;amp&#39;: [.., ..], ...}
    bounds_dict : dict
        dict holding bound options for each parameter type, e.g.
        {&#34;pos_range&#34;: 5.0, &#34;amp_bounds&#34;: [0.0, 1.0], ...}
    *aoi_coords : tuple of 4-tuples
        As elsewhere
    norm : str default=&#34;div&#34;
        Normalisation method

    Optional parameters passed to cpufit
    ------------------------------------
    tolerance : float = 1e-12
        Fit tolerance threshold
    max_iterations : int = 50
        Maximum fit iterations permitted.
    estimator_id : str = &#34;LSE&#34;
        Estimator to use, &#34;LSE&#34; or &#34;MLE&#34; (least squares or maximum likelihood).
        MLE for Poisson, assuming all noise in data is purely Poissonian.

    Returns
    -------
    fit_image_results : dict
        Format: {&#34;AOI_n&#34;: {&#34;scipyfit&#34;: AoiAvgFit}, ...}
    &#34;&#34;&#34;
    pguess, pbounds = _gen_cf_guesses_bounds(
        fit_model, *dukit.pl.common.gen_init_guesses(fit_model, guess_dict, bounds_dict)
    )
    # only fit the params we want to :)
    params_to_fit = _get_params_to_fit(fit_model)
    # need to repeat everything, as cpufit expects 2D array
    guess = np.repeat([pguess], repeats=2, axis=0).astype(dtype=np.float32)
    constraints = np.repeat([pbounds], repeats=2, axis=0).astype(dtype=np.float32)
    constraint_types = np.array(
        [cf.ConstraintType.LOWER_UPPER for i in range(len(params_to_fit))]
    ).astype(np.int32)

    model_id = _get_cpufit_modelID(fit_model)

    estimator_id = {&#34;LSE&#34;: cf.EstimatorID.LSE, &#34;MLE&#34;: cf.EstimatorID.MLE}.get(
        estimator_id, cf.EstimatorID.LSE
    )

    aois = dukit.itool.get_aois(np.shape(sig), *aoi_coords)

    # add the single pixel check on (just for output)
    output_aoi_coords = list(aoi_coords)
    shp = np.shape(sig)[:-1]
    output_aoi_coords.insert(
        0, (shp[0] // 2, shp[1] // 2, shp[0] // 2 + 1, shp[1] // 2 + 1)
    )

    ret = {}
    for i, a in enumerate(aois):
        s = sig[a[0], a[1], :]
        r = ref[a[0], a[1], :]
        if norm == &#34;div&#34;:
            avg_sig_norm = np.nanmean(s / r, axis=(0, 1))
        elif norm == &#34;sub&#34;:
            avg_sig_norm = np.nanmean(1 + (s - r) / (s + r), axis=(0, 1))
        elif norm == &#34;true_sub&#34;:
            avg_sig_norm = np.nanmean((s - r) / np.nanmax(s - r).reshape(
                s.shape[:-1] + (1,)
            ), axis=(0, 1))

        avg_sig = np.nanmean(s, axis=(0, 1))
        avg_ref = np.nanmean(r, axis=(0, 1))

        this_aoi_twice = np.repeat([avg_sig_norm], repeats=2, axis=0).astype(np.float32)
        best_params_cf, _, _, _, _ = cf.fit_constrained(
            this_aoi_twice,
            None,
            model_id,
            guess,
            constraints=constraints,
            constraint_types=constraint_types,
            user_info=sweep_arr.astype(dtype=np.float32),
            parameters_to_fit=params_to_fit,
            estimator_id=estimator_id,
            tolerance=tolerance,
            max_number_iterations=max_iterations,
        )
        best_params = best_params_cf[0, :]  # just take first fit
        # manually compute sigmas, using analytic jacobian etc.
        best_sigmas = dukit.pl.common.calc_sigmas(
            fit_model, sweep_arr, avg_sig_norm, best_params
        )
        best_residual = fit_model(best_params, sweep_arr) - avg_sig_norm

        fit_xvec = np.linspace(
            np.min(sweep_arr),
            np.max(sweep_arr),
            10000,
        )
        fit_yvec = fit_model(best_params, fit_xvec)
        fit_yvec = fit_model(best_params, fit_xvec)
        ret[f&#34;AOI_{i}&#34;] = {
            &#34;cpufit&#34;: dukit.share.AoiAvgFit(
                i,
                sweep_arr,
                avg_sig_norm,
                avg_sig,
                avg_ref,
                &#34;cpufit&#34;,
                fit_xvec,
                fit_yvec,
                best_params,
                best_sigmas,
                best_residual,
                pguess,
                pbounds,
                output_aoi_coords[i],
            )
        }

    return ret


# ==========================================================================


def fit_all_pixels_pl(
    sig_norm: npt.NDArray,
    sweep_arr: npt.NDArray,
    fit_model: &#34;dukit.pl.model.FitModel&#34;,
    guess_dict: dict,
    bounds_dict: dict,
    roi_avg_result: dukit.share.RoiAvgFit | None = None,
    estimator_id: str = &#34;LSE&#34;,
    tolerance: float = 1e-12,
    max_iterations: int = 50,
):
    &#34;&#34;&#34;
    Fits each pixel and returns dictionary of param_name -&gt; param_image.

    Arguments
    ---------
    sig_norm : np array, 3D
        Normalised measurement array, shape: [sweep_arr, y, x].
    sweep_arr : np array, 1D
        Affine parameter list (e.g. tau or freq)
    fit_model : dukit.pl.model.FitModel
        The model we&#39;re fitting to.
    guess_dict : dict
        Format: key -&gt; list of guesses for each independent version of that fn_type.
        e.g. &#39;pos&#39;: [.., ..] for each pos fn_type.
    bounds_dict : dict
        Format: key -&gt; bounds for that param type (or use _range).
        e.g. &#39;pos_bounds&#39;: [5., 25.]
        or &#39;pos_range&#39;: 5.0
    roi_avg_result : dukit.share.RoiAvgFit | None
        The result of fitting the ROI average.
        If done, directly uses guesses provided.
    n_jobs : int, default=-2
        Number of jobs to run concurrently, see joblib docs.
        -2 === leaving one cpu free, etc. for neg numbers.
    joblib_verbosity:int = 5
        How often to update progress bar.

    Optional parameters passed to cpufit
    ------------------------------------
    tolerance : float = 1e-12
        Fit tolerance threshold
    max_iterations : int = 50
        Maximum fit iterations permitted.
    estimator_id : str = &#34;LSE&#34;
        Estimator to use, &#34;LSE&#34; or &#34;MLE&#34; (least squares or maximum likelihood).
        MLE for Poisson, assuming all noise in data is purely Poissonian.

    Returns
    -------
    fit_image_results : dict
        Dictionary, key: param_keys, val: image (2D) of param values across FOV.
        Also has &#39;residual_0&#39; as a key.
        Sigmas (stdev on fit error) are given as e.g. pos_0_sigma
    &#34;&#34;&#34;
    num_pixels = np.shape(sig_norm)[0] * np.shape(sig_norm)[1]

    init_pguess, pbounds = _gen_cf_guesses_bounds(
        fit_model, *dukit.pl.common.gen_init_guesses(fit_model, guess_dict, bounds_dict)
    )
    pguess = roi_avg_result.best_params if roi_avg_result is not None else init_pguess
    # only fit the params we want to :)
    params_to_fit = _get_params_to_fit(fit_model)

    guess_params = np.array([pguess], dtype=np.float32)
    guess = np.repeat(guess_params, repeats=num_pixels, axis=0)

    model_id = _get_cpufit_modelID(fit_model)
    estimator_id = {&#34;LSE&#34;: cf.EstimatorID.LSE, &#34;MLE&#34;: cf.EstimatorID.MLE}.get(
        estimator_id, cf.EstimatorID.LSE
    )

    constraint_types = np.array(
        [cf.ConstraintType.LOWER_UPPER for i in range(len(params_to_fit))]
    ).astype(np.int32)

    # constraints needs to be reshaped too
    constraints = np.repeat([pbounds], repeats=num_pixels, axis=0).astype(
        dtype=np.float32
    )

    # shape data as wanted by cpufit (num_pixels, num_sweeps)
    sig_norm_shaped = sig_norm.reshape(num_pixels, -1).astype(dtype=np.float32)

    fitting_results, _, _, _, execution_time = cf.fit_constrained(
        sig_norm_shaped,
        None,
        model_id,
        guess,
        constraints=constraints,
        constraint_types=constraint_types,
        user_info=sweep_arr.astype(dtype=np.float32),
        parameters_to_fit=params_to_fit,
        estimator_id=estimator_id,
        tolerance=tolerance,
        max_number_iterations=max_iterations,
    )
    logging.info(f&#34;fit time: {execution_time:.2f}s&#34;)

    # unsure if this will work...
    results_arr = np.array(fitting_results).reshape((*sig_norm.shape[:2], len(pguess)))

    names = list(fit_model.get_param_odict().keys())
    fit_image_results = {
        name: array
        for name, array in zip(names, dukit.itool._iterframe(results_arr))
    }

    # add residual_0 image
    fit_image_results[&#34;residual_0&#34;] = np.reshape(
        list(
            map(
                lambda y, p: np.sum(y - fit_model(p, sweep_arr)),
                sig_norm_shaped,
                fitting_results,
            ),
        ),
        sig_norm.shape[:2],
    )

    # calc sigmas &amp; get correct shape - not particularly efficient here
    # be careful with sizes, we only want the parameters actually fit
    sigmas_shaped = np.full((num_pixels, len(names)), np.nan)
    for pl_vec, fitp, sigma_vec in zip(sig_norm_shaped, fitting_results, sigmas_shaped):
        sigma_vec[:] = dukit.pl.common.calc_sigmas(fit_model, sweep_arr, pl_vec, fitp)
    sigmas_result = sigmas_shaped.reshape((*sig_norm.shape[:2], len(names)))

    for i, _ in enumerate(names):
        fit_image_results[f&#34;sigma_{names[i]}&#34;] = sigmas_result[:, :, i]
    return fit_image_results


# =======================================================================================


def _gen_cf_guesses_bounds(
    fit_model: &#34;dukit.pl.model.FitModel&#34;, init_guesses: dict, init_bounds: dict
) -&gt; tuple[npt.NDArray, npt.NDArray]:
    &#34;&#34;&#34;
    Generate arrays of initial fit guesses and bounds in correct form for cpufit

    init_guesses and init_bounds are dictionaries up to this point, we now convert to
    np arrays, that scipy will recognise. In particular, we specificy that each of the
    &#39;num&#39; of each &#39;fn_type&#39; have independent parameters, so must have independent
    init_guesses and init_bounds when plugged into scipy.

    Arguments
    ---------
    fit_model : dukit.pl.model.FitModel
        Model definition.
    init_guesses : dict
        Dict holding guesses for each parameter,
         e.g. key -&gt; list of guesses for each independent version of that fn_type.
    init_bounds : dict
        Dict holding guesses for each parameter,
        e.g. key -&gt; list of bounds for each independent version of that fn_type.

    Returns
    -------
    fit_param_ar : np array, shape: num_params
        The initial fit parameter guesses.
    fit_param_bound_ar : np array, shape: (num_params, 2)
        Fit parameter bounds.
    &#34;&#34;&#34;
    param_lst = []
    bound_lst = []

    for param_name in fit_model.get_param_odict():
        split_param = param_name.split(&#34;_&#34;)
        param_num_str = int(split_param[-1])
        param_key = &#34;_&#34;.join(split_param[:-1])
        param_num = int(param_num_str)  # i.e. pos_0
        try:
            param_lst.append(init_guesses[param_key][param_num])
        except (TypeError, KeyError, IndexError):
            param_lst.append(init_guesses[param_key])
        if len(np.array(init_bounds[param_key]).shape) == 2:
            bound_lst.append(init_bounds[param_key][param_num][0])
            bound_lst.append(init_bounds[param_key][param_num][1])
        else:
            bound_lst.append(init_bounds[param_key][0])
            bound_lst.append(init_bounds[param_key][1])

    # now need to go through and make sure we have enough if its a lorentz
    # (model expects 8 lorentzians)
    expected_n_params = 0  # default: don&#39;t do anything
    if isinstance(fit_model, dukit.pl.model.LinearLorentzians):
        expected_n_params = 2 + 3 * 8
    if isinstance(fit_model, dukit.pl.model.ConstLorentzians):
        expected_n_params = 1 + 3 * 8
    while len(param_lst) &lt; expected_n_params:
        param_lst.append(0)
    while len(bound_lst) &lt; 2 * expected_n_params:
        bound_lst.append(0)
        bound_lst.append(1)

    return np.array(param_lst), np.array(bound_lst)


def _get_params_to_fit(fit_model: &#34;dukit.pl.model.FitModel&#34;) -&gt; npt.NDArray[np.int32]:
    model_id = _get_cpufit_modelID(fit_model)
    if model_id in [
        cf.ModelID.LORENTZ8_CONST,
        cf.ModelID.LORENTZ8_LINEAR,
    ]:
        num_lorentzians = fit_model.n_lorentzians
        if model_id == cf.ModelID.LORENTZ8_CONST:
            params_to_fit = [1 for i in range(3 * num_lorentzians + 1)]  # + 1 for const
            num_params = 25
        elif model_id == cf.ModelID.LORENTZ8_LINEAR:
            params_to_fit = [1 for i in range(3 * num_lorentzians + 2)]  # + 2 for c, m
            num_params = 26
        while len(params_to_fit) &lt; num_params:
            params_to_fit.append(0)
    else:
        params_to_fit = [1 for i in range(len(fit_model.get_param_defn()))]

    return np.array(params_to_fit, dtype=np.int32)</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-functions">Functions</h2>
<dl>
<dt id="dukit.pl.cpufit._gen_cf_guesses_bounds"><code class="name flex">
<span>def <span class="ident">_gen_cf_guesses_bounds</span></span>(<span>fit_model:Â <a title="dukit.pl.model.FitModel" href="model.html#dukit.pl.model.FitModel">FitModel</a>, init_guesses:Â dict, init_bounds:Â dict) â€‘>Â tuple[numpy.ndarray[typing.Any,Â numpy.dtype[+_ScalarType_co]],Â numpy.ndarray[typing.Any,Â numpy.dtype[+_ScalarType_co]]]</span>
</code></dt>
<dd>
<div class="desc"><p>Generate arrays of initial fit guesses and bounds in correct form for cpufit</p>
<p>init_guesses and init_bounds are dictionaries up to this point, we now convert to
np arrays, that scipy will recognise. In particular, we specificy that each of the
'num' of each 'fn_type' have independent parameters, so must have independent
init_guesses and init_bounds when plugged into scipy.</p>
<h2 id="arguments">Arguments</h2>
<dl>
<dt><strong><code>fit_model</code></strong> :&ensp;<code><a title="dukit.pl.model.FitModel" href="model.html#dukit.pl.model.FitModel">FitModel</a></code></dt>
<dd>Model definition.</dd>
<dt><strong><code>init_guesses</code></strong> :&ensp;<code>dict</code></dt>
<dd>Dict holding guesses for each parameter,
e.g. key -&gt; list of guesses for each independent version of that fn_type.</dd>
<dt><strong><code>init_bounds</code></strong> :&ensp;<code>dict</code></dt>
<dd>Dict holding guesses for each parameter,
e.g. key -&gt; list of bounds for each independent version of that fn_type.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>fit_param_ar</code></strong> :&ensp;<code>np array, shape: num_params</code></dt>
<dd>The initial fit parameter guesses.</dd>
<dt><strong><code>fit_param_bound_ar</code></strong> :&ensp;<code>np array, shape: (num_params, 2)</code></dt>
<dd>Fit parameter bounds.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def _gen_cf_guesses_bounds(
    fit_model: &#34;dukit.pl.model.FitModel&#34;, init_guesses: dict, init_bounds: dict
) -&gt; tuple[npt.NDArray, npt.NDArray]:
    &#34;&#34;&#34;
    Generate arrays of initial fit guesses and bounds in correct form for cpufit

    init_guesses and init_bounds are dictionaries up to this point, we now convert to
    np arrays, that scipy will recognise. In particular, we specificy that each of the
    &#39;num&#39; of each &#39;fn_type&#39; have independent parameters, so must have independent
    init_guesses and init_bounds when plugged into scipy.

    Arguments
    ---------
    fit_model : dukit.pl.model.FitModel
        Model definition.
    init_guesses : dict
        Dict holding guesses for each parameter,
         e.g. key -&gt; list of guesses for each independent version of that fn_type.
    init_bounds : dict
        Dict holding guesses for each parameter,
        e.g. key -&gt; list of bounds for each independent version of that fn_type.

    Returns
    -------
    fit_param_ar : np array, shape: num_params
        The initial fit parameter guesses.
    fit_param_bound_ar : np array, shape: (num_params, 2)
        Fit parameter bounds.
    &#34;&#34;&#34;
    param_lst = []
    bound_lst = []

    for param_name in fit_model.get_param_odict():
        split_param = param_name.split(&#34;_&#34;)
        param_num_str = int(split_param[-1])
        param_key = &#34;_&#34;.join(split_param[:-1])
        param_num = int(param_num_str)  # i.e. pos_0
        try:
            param_lst.append(init_guesses[param_key][param_num])
        except (TypeError, KeyError, IndexError):
            param_lst.append(init_guesses[param_key])
        if len(np.array(init_bounds[param_key]).shape) == 2:
            bound_lst.append(init_bounds[param_key][param_num][0])
            bound_lst.append(init_bounds[param_key][param_num][1])
        else:
            bound_lst.append(init_bounds[param_key][0])
            bound_lst.append(init_bounds[param_key][1])

    # now need to go through and make sure we have enough if its a lorentz
    # (model expects 8 lorentzians)
    expected_n_params = 0  # default: don&#39;t do anything
    if isinstance(fit_model, dukit.pl.model.LinearLorentzians):
        expected_n_params = 2 + 3 * 8
    if isinstance(fit_model, dukit.pl.model.ConstLorentzians):
        expected_n_params = 1 + 3 * 8
    while len(param_lst) &lt; expected_n_params:
        param_lst.append(0)
    while len(bound_lst) &lt; 2 * expected_n_params:
        bound_lst.append(0)
        bound_lst.append(1)

    return np.array(param_lst), np.array(bound_lst)</code></pre>
</details>
</dd>
<dt id="dukit.pl.cpufit.fit_all_pixels_pl"><code class="name flex">
<span>def <span class="ident">fit_all_pixels_pl</span></span>(<span>sig_norm:Â numpy.ndarray[typing.Any,Â numpy.dtype[+_ScalarType_co]], sweep_arr:Â numpy.ndarray[typing.Any,Â numpy.dtype[+_ScalarType_co]], fit_model:Â <a title="dukit.pl.model.FitModel" href="model.html#dukit.pl.model.FitModel">FitModel</a>, guess_dict:Â dict, bounds_dict:Â dict, roi_avg_result:Â <a title="dukit.share.RoiAvgFit" href="../share.html#dukit.share.RoiAvgFit">RoiAvgFit</a>Â |Â NoneÂ =Â None, estimator_id:Â strÂ =Â 'LSE', tolerance:Â floatÂ =Â 1e-12, max_iterations:Â intÂ =Â 50)</span>
</code></dt>
<dd>
<div class="desc"><p>Fits each pixel and returns dictionary of param_name -&gt; param_image.</p>
<h2 id="arguments">Arguments</h2>
<dl>
<dt><strong><code>sig_norm</code></strong> :&ensp;<code>np array, 3D</code></dt>
<dd>Normalised measurement array, shape: [sweep_arr, y, x].</dd>
<dt><strong><code>sweep_arr</code></strong> :&ensp;<code>np array, 1D</code></dt>
<dd>Affine parameter list (e.g. tau or freq)</dd>
<dt><strong><code>fit_model</code></strong> :&ensp;<code><a title="dukit.pl.model.FitModel" href="model.html#dukit.pl.model.FitModel">FitModel</a></code></dt>
<dd>The model we're fitting to.</dd>
<dt><strong><code>guess_dict</code></strong> :&ensp;<code>dict</code></dt>
<dd>Format: key -&gt; list of guesses for each independent version of that fn_type.
e.g. 'pos': [.., ..] for each pos fn_type.</dd>
<dt><strong><code>bounds_dict</code></strong> :&ensp;<code>dict</code></dt>
<dd>Format: key -&gt; bounds for that param type (or use _range).
e.g. 'pos_bounds': [5., 25.]
or 'pos_range': 5.0</dd>
<dt><strong><code>roi_avg_result</code></strong> :&ensp;<code>dukit.share.RoiAvgFit | None</code></dt>
<dd>The result of fitting the ROI average.
If done, directly uses guesses provided.</dd>
<dt><strong><code>n_jobs</code></strong> :&ensp;<code>int</code>, default=<code>-2</code></dt>
<dd>Number of jobs to run concurrently, see joblib docs.
-2 === leaving one cpu free, etc. for neg numbers.</dd>
</dl>
<p>joblib_verbosity:int = 5
How often to update progress bar.</p>
<h2 id="optional-parameters-passed-to-cpufit">Optional Parameters Passed To Cpufit</h2>
<p>tolerance : float = 1e-12
Fit tolerance threshold
max_iterations : int = 50
Maximum fit iterations permitted.
estimator_id : str = "LSE"
Estimator to use, "LSE" or "MLE" (least squares or maximum likelihood).
MLE for Poisson, assuming all noise in data is purely Poissonian.</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>fit_image_results</code></strong> :&ensp;<code>dict</code></dt>
<dd>Dictionary, key: param_keys, val: image (2D) of param values across FOV.
Also has 'residual_0' as a key.
Sigmas (stdev on fit error) are given as e.g. pos_0_sigma</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def fit_all_pixels_pl(
    sig_norm: npt.NDArray,
    sweep_arr: npt.NDArray,
    fit_model: &#34;dukit.pl.model.FitModel&#34;,
    guess_dict: dict,
    bounds_dict: dict,
    roi_avg_result: dukit.share.RoiAvgFit | None = None,
    estimator_id: str = &#34;LSE&#34;,
    tolerance: float = 1e-12,
    max_iterations: int = 50,
):
    &#34;&#34;&#34;
    Fits each pixel and returns dictionary of param_name -&gt; param_image.

    Arguments
    ---------
    sig_norm : np array, 3D
        Normalised measurement array, shape: [sweep_arr, y, x].
    sweep_arr : np array, 1D
        Affine parameter list (e.g. tau or freq)
    fit_model : dukit.pl.model.FitModel
        The model we&#39;re fitting to.
    guess_dict : dict
        Format: key -&gt; list of guesses for each independent version of that fn_type.
        e.g. &#39;pos&#39;: [.., ..] for each pos fn_type.
    bounds_dict : dict
        Format: key -&gt; bounds for that param type (or use _range).
        e.g. &#39;pos_bounds&#39;: [5., 25.]
        or &#39;pos_range&#39;: 5.0
    roi_avg_result : dukit.share.RoiAvgFit | None
        The result of fitting the ROI average.
        If done, directly uses guesses provided.
    n_jobs : int, default=-2
        Number of jobs to run concurrently, see joblib docs.
        -2 === leaving one cpu free, etc. for neg numbers.
    joblib_verbosity:int = 5
        How often to update progress bar.

    Optional parameters passed to cpufit
    ------------------------------------
    tolerance : float = 1e-12
        Fit tolerance threshold
    max_iterations : int = 50
        Maximum fit iterations permitted.
    estimator_id : str = &#34;LSE&#34;
        Estimator to use, &#34;LSE&#34; or &#34;MLE&#34; (least squares or maximum likelihood).
        MLE for Poisson, assuming all noise in data is purely Poissonian.

    Returns
    -------
    fit_image_results : dict
        Dictionary, key: param_keys, val: image (2D) of param values across FOV.
        Also has &#39;residual_0&#39; as a key.
        Sigmas (stdev on fit error) are given as e.g. pos_0_sigma
    &#34;&#34;&#34;
    num_pixels = np.shape(sig_norm)[0] * np.shape(sig_norm)[1]

    init_pguess, pbounds = _gen_cf_guesses_bounds(
        fit_model, *dukit.pl.common.gen_init_guesses(fit_model, guess_dict, bounds_dict)
    )
    pguess = roi_avg_result.best_params if roi_avg_result is not None else init_pguess
    # only fit the params we want to :)
    params_to_fit = _get_params_to_fit(fit_model)

    guess_params = np.array([pguess], dtype=np.float32)
    guess = np.repeat(guess_params, repeats=num_pixels, axis=0)

    model_id = _get_cpufit_modelID(fit_model)
    estimator_id = {&#34;LSE&#34;: cf.EstimatorID.LSE, &#34;MLE&#34;: cf.EstimatorID.MLE}.get(
        estimator_id, cf.EstimatorID.LSE
    )

    constraint_types = np.array(
        [cf.ConstraintType.LOWER_UPPER for i in range(len(params_to_fit))]
    ).astype(np.int32)

    # constraints needs to be reshaped too
    constraints = np.repeat([pbounds], repeats=num_pixels, axis=0).astype(
        dtype=np.float32
    )

    # shape data as wanted by cpufit (num_pixels, num_sweeps)
    sig_norm_shaped = sig_norm.reshape(num_pixels, -1).astype(dtype=np.float32)

    fitting_results, _, _, _, execution_time = cf.fit_constrained(
        sig_norm_shaped,
        None,
        model_id,
        guess,
        constraints=constraints,
        constraint_types=constraint_types,
        user_info=sweep_arr.astype(dtype=np.float32),
        parameters_to_fit=params_to_fit,
        estimator_id=estimator_id,
        tolerance=tolerance,
        max_number_iterations=max_iterations,
    )
    logging.info(f&#34;fit time: {execution_time:.2f}s&#34;)

    # unsure if this will work...
    results_arr = np.array(fitting_results).reshape((*sig_norm.shape[:2], len(pguess)))

    names = list(fit_model.get_param_odict().keys())
    fit_image_results = {
        name: array
        for name, array in zip(names, dukit.itool._iterframe(results_arr))
    }

    # add residual_0 image
    fit_image_results[&#34;residual_0&#34;] = np.reshape(
        list(
            map(
                lambda y, p: np.sum(y - fit_model(p, sweep_arr)),
                sig_norm_shaped,
                fitting_results,
            ),
        ),
        sig_norm.shape[:2],
    )

    # calc sigmas &amp; get correct shape - not particularly efficient here
    # be careful with sizes, we only want the parameters actually fit
    sigmas_shaped = np.full((num_pixels, len(names)), np.nan)
    for pl_vec, fitp, sigma_vec in zip(sig_norm_shaped, fitting_results, sigmas_shaped):
        sigma_vec[:] = dukit.pl.common.calc_sigmas(fit_model, sweep_arr, pl_vec, fitp)
    sigmas_result = sigmas_shaped.reshape((*sig_norm.shape[:2], len(names)))

    for i, _ in enumerate(names):
        fit_image_results[f&#34;sigma_{names[i]}&#34;] = sigmas_result[:, :, i]
    return fit_image_results</code></pre>
</details>
</dd>
<dt id="dukit.pl.cpufit.fit_aois_pl"><code class="name flex">
<span>def <span class="ident">fit_aois_pl</span></span>(<span>sig:Â numpy.ndarray[typing.Any,Â numpy.dtype[+_ScalarType_co]], ref:Â numpy.ndarray[typing.Any,Â numpy.dtype[+_ScalarType_co]], sweep_arr:Â numpy.ndarray[typing.Any,Â numpy.dtype[+_ScalarType_co]], fit_model:Â <a title="dukit.pl.model.FitModel" href="model.html#dukit.pl.model.FitModel">FitModel</a>, guess_dict:Â dict, bounds_dict:Â dict, *aoi_coords:Â tuple[int,Â int,Â int,Â int], norm:Â strÂ =Â 'div', estimator_id:Â strÂ =Â 'LSE', tolerance:Â floatÂ =Â 1e-12, max_iterations:Â intÂ =Â 50) â€‘>Â dict[str,Â dict[str,Â <a title="dukit.share.AoiAvgFit" href="../share.html#dukit.share.AoiAvgFit">AoiAvgFit</a>]]</span>
</code></dt>
<dd>
<div class="desc"><p>Fit AOI averages</p>
<h2 id="arguments">Arguments</h2>
<dl>
<dt><strong><code>sig</code></strong> :&ensp;<code>np array, 3D</code></dt>
<dd>Sig measurement array, shape: [y, x, sweep_arr].</dd>
<dt><strong><code>ref</code></strong> :&ensp;<code>np array, 3D</code></dt>
<dd>Ref measurement array, shape: [y, x, sweep_arr].</dd>
<dt><strong><code>sweep_arr</code></strong> :&ensp;<code>np array, 1D</code></dt>
<dd>Affine parameter list (e.g. tau or freq)</dd>
<dt><strong><code>fit_model</code></strong> :&ensp;<code><a title="dukit.pl.model.FitModel" href="model.html#dukit.pl.model.FitModel">FitModel</a></code></dt>
<dd>The model we're fitting to.</dd>
<dt><strong><code>guess_dict</code></strong> :&ensp;<code>dict</code></dt>
<dd _.._="[..," _amp_:="'amp':" _pos_:="'pos':" class=".], .], ..">dict holding guesses for each parameter type, e.g.</dd>
<dt><strong><code>bounds_dict</code></strong> :&ensp;<code>dict</code></dt>
<dd 1.0_="1.0]," 5.0_="5.0," _0.0_="[0.0," _amp_bounds_:="&quot;amp_bounds&quot;:" _pos_range_:="&quot;pos_range&quot;:" class="..">dict holding bound options for each parameter type, e.g.</dd>
<dt><strong><code>*aoi_coords</code></strong> :&ensp;<code>tuple</code> of <code>4-tuples</code></dt>
<dd>As elsewhere</dd>
<dt><strong><code>norm</code></strong> :&ensp;<code>str default="div"</code></dt>
<dd>Normalisation method</dd>
</dl>
<h2 id="optional-parameters-passed-to-cpufit">Optional Parameters Passed To Cpufit</h2>
<p>tolerance : float = 1e-12
Fit tolerance threshold
max_iterations : int = 50
Maximum fit iterations permitted.
estimator_id : str = "LSE"
Estimator to use, "LSE" or "MLE" (least squares or maximum likelihood).
MLE for Poisson, assuming all noise in data is purely Poissonian.</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>fit_image_results</code></strong> :&ensp;<code>dict</code></dt>
<dd>Format: {"AOI_n": {"scipyfit": AoiAvgFit}, &hellip;}</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def fit_aois_pl(
    sig: npt.NDArray,
    ref: npt.NDArray,
    sweep_arr: npt.NDArray,
    fit_model: &#34;dukit.pl.model.FitModel&#34;,
    guess_dict: dict,
    bounds_dict: dict,
    *aoi_coords: tuple[int, int, int, int],
    norm: str = &#34;div&#34;,
    estimator_id: str = &#34;LSE&#34;,
    tolerance: float = 1e-12,
    max_iterations: int = 50,
) -&gt; dict[str, dict[str, dukit.share.AoiAvgFit]]:
    &#34;&#34;&#34;
    Fit AOI averages

    Arguments
    ---------
    sig : np array, 3D
        Sig measurement array, shape: [y, x, sweep_arr].
    ref : np array, 3D
        Ref measurement array, shape: [y, x, sweep_arr].
    sweep_arr : np array, 1D
        Affine parameter list (e.g. tau or freq)
    fit_model : dukit.pl.model.FitModel
        The model we&#39;re fitting to.
    guess_dict : dict
        dict holding guesses for each parameter type, e.g.
        {&#39;pos&#39;: [.., ..], &#39;amp&#39;: [.., ..], ...}
    bounds_dict : dict
        dict holding bound options for each parameter type, e.g.
        {&#34;pos_range&#34;: 5.0, &#34;amp_bounds&#34;: [0.0, 1.0], ...}
    *aoi_coords : tuple of 4-tuples
        As elsewhere
    norm : str default=&#34;div&#34;
        Normalisation method

    Optional parameters passed to cpufit
    ------------------------------------
    tolerance : float = 1e-12
        Fit tolerance threshold
    max_iterations : int = 50
        Maximum fit iterations permitted.
    estimator_id : str = &#34;LSE&#34;
        Estimator to use, &#34;LSE&#34; or &#34;MLE&#34; (least squares or maximum likelihood).
        MLE for Poisson, assuming all noise in data is purely Poissonian.

    Returns
    -------
    fit_image_results : dict
        Format: {&#34;AOI_n&#34;: {&#34;scipyfit&#34;: AoiAvgFit}, ...}
    &#34;&#34;&#34;
    pguess, pbounds = _gen_cf_guesses_bounds(
        fit_model, *dukit.pl.common.gen_init_guesses(fit_model, guess_dict, bounds_dict)
    )
    # only fit the params we want to :)
    params_to_fit = _get_params_to_fit(fit_model)
    # need to repeat everything, as cpufit expects 2D array
    guess = np.repeat([pguess], repeats=2, axis=0).astype(dtype=np.float32)
    constraints = np.repeat([pbounds], repeats=2, axis=0).astype(dtype=np.float32)
    constraint_types = np.array(
        [cf.ConstraintType.LOWER_UPPER for i in range(len(params_to_fit))]
    ).astype(np.int32)

    model_id = _get_cpufit_modelID(fit_model)

    estimator_id = {&#34;LSE&#34;: cf.EstimatorID.LSE, &#34;MLE&#34;: cf.EstimatorID.MLE}.get(
        estimator_id, cf.EstimatorID.LSE
    )

    aois = dukit.itool.get_aois(np.shape(sig), *aoi_coords)

    # add the single pixel check on (just for output)
    output_aoi_coords = list(aoi_coords)
    shp = np.shape(sig)[:-1]
    output_aoi_coords.insert(
        0, (shp[0] // 2, shp[1] // 2, shp[0] // 2 + 1, shp[1] // 2 + 1)
    )

    ret = {}
    for i, a in enumerate(aois):
        s = sig[a[0], a[1], :]
        r = ref[a[0], a[1], :]
        if norm == &#34;div&#34;:
            avg_sig_norm = np.nanmean(s / r, axis=(0, 1))
        elif norm == &#34;sub&#34;:
            avg_sig_norm = np.nanmean(1 + (s - r) / (s + r), axis=(0, 1))
        elif norm == &#34;true_sub&#34;:
            avg_sig_norm = np.nanmean((s - r) / np.nanmax(s - r).reshape(
                s.shape[:-1] + (1,)
            ), axis=(0, 1))

        avg_sig = np.nanmean(s, axis=(0, 1))
        avg_ref = np.nanmean(r, axis=(0, 1))

        this_aoi_twice = np.repeat([avg_sig_norm], repeats=2, axis=0).astype(np.float32)
        best_params_cf, _, _, _, _ = cf.fit_constrained(
            this_aoi_twice,
            None,
            model_id,
            guess,
            constraints=constraints,
            constraint_types=constraint_types,
            user_info=sweep_arr.astype(dtype=np.float32),
            parameters_to_fit=params_to_fit,
            estimator_id=estimator_id,
            tolerance=tolerance,
            max_number_iterations=max_iterations,
        )
        best_params = best_params_cf[0, :]  # just take first fit
        # manually compute sigmas, using analytic jacobian etc.
        best_sigmas = dukit.pl.common.calc_sigmas(
            fit_model, sweep_arr, avg_sig_norm, best_params
        )
        best_residual = fit_model(best_params, sweep_arr) - avg_sig_norm

        fit_xvec = np.linspace(
            np.min(sweep_arr),
            np.max(sweep_arr),
            10000,
        )
        fit_yvec = fit_model(best_params, fit_xvec)
        fit_yvec = fit_model(best_params, fit_xvec)
        ret[f&#34;AOI_{i}&#34;] = {
            &#34;cpufit&#34;: dukit.share.AoiAvgFit(
                i,
                sweep_arr,
                avg_sig_norm,
                avg_sig,
                avg_ref,
                &#34;cpufit&#34;,
                fit_xvec,
                fit_yvec,
                best_params,
                best_sigmas,
                best_residual,
                pguess,
                pbounds,
                output_aoi_coords[i],
            )
        }

    return ret</code></pre>
</details>
</dd>
<dt id="dukit.pl.cpufit.fit_roi_avg_pl"><code class="name flex">
<span>def <span class="ident">fit_roi_avg_pl</span></span>(<span>sig:Â numpy.ndarray[typing.Any,Â numpy.dtype[+_ScalarType_co]], ref:Â numpy.ndarray[typing.Any,Â numpy.dtype[+_ScalarType_co]], sweep_arr:Â numpy.ndarray[typing.Any,Â numpy.dtype[+_ScalarType_co]], fit_model:Â <a title="dukit.pl.model.FitModel" href="model.html#dukit.pl.model.FitModel">FitModel</a>, guess_dict:Â dict, bounds_dict:Â dict, norm:Â strÂ =Â 'div', estimator_id:Â strÂ =Â 'LSE', tolerance:Â floatÂ =Â 1e-12, max_iterations:Â intÂ =Â 50)</span>
</code></dt>
<dd>
<div class="desc"><p>Fit AOI averages</p>
<h2 id="arguments">Arguments</h2>
<dl>
<dt><strong><code>sig</code></strong> :&ensp;<code>np array, 3D</code></dt>
<dd>Sig measurement array, shape: [y, x, sweep_arr]. CROPPED etc. already.</dd>
<dt><strong><code>ref</code></strong> :&ensp;<code>np array, 3D</code></dt>
<dd>Ref measurement array, shape: [y, x, sweep_arr]. CROPPED etc. already.</dd>
<dt><strong><code>sweep_arr</code></strong> :&ensp;<code>np array, 1D</code></dt>
<dd>Affine parameter list (e.g. tau or freq)</dd>
<dt><strong><code>fit_model</code></strong> :&ensp;<code><a title="dukit.pl.model.FitModel" href="model.html#dukit.pl.model.FitModel">FitModel</a></code></dt>
<dd>The model we're fitting to.</dd>
<dt><strong><code>guess_dict</code></strong> :&ensp;<code>dict</code></dt>
<dd _.._="[..," _amp_:="'amp':" _pos_:="'pos':" class=".], .], ..">dict holding guesses for each parameter type, e.g.</dd>
<dt><strong><code>bounds_dict</code></strong> :&ensp;<code>dict</code></dt>
<dd 1.0_="1.0]," 5.0_="5.0," _0.0_="[0.0," _amp_bounds_:="&quot;amp_bounds&quot;:" _pos_range_:="&quot;pos_range&quot;:" class="..">dict holding bound options for each parameter type, e.g.</dd>
<dt><strong><code>norm</code></strong> :&ensp;<code>str default="div"</code></dt>
<dd>Normalisation method</dd>
</dl>
<h2 id="optional-parameters-passed-to-cpufit">Optional Parameters Passed To Cpufit</h2>
<p>tolerance : float = 1e-12
Fit tolerance threshold
max_iterations : int = 50
Maximum fit iterations permitted.
estimator_id : str = "LSE"
Estimator to use, "LSE" or "MLE" (least squares or maximum likelihood).
MLE for Poisson, assuming all noise in data is purely Poissonian.</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>fit_image_results</code></strong> :&ensp;<code><a title="dukit.share.RoiAvgFit" href="../share.html#dukit.share.RoiAvgFit">RoiAvgFit</a></code></dt>
<dd>&nbsp;</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def fit_roi_avg_pl(
    sig: npt.NDArray,
    ref: npt.NDArray,
    sweep_arr: npt.NDArray,
    fit_model: &#34;dukit.pl.model.FitModel&#34;,
    guess_dict: dict,
    bounds_dict: dict,
    norm: str = &#34;div&#34;,
    estimator_id: str = &#34;LSE&#34;,
    tolerance: float = 1e-12,
    max_iterations: int = 50,
):
    &#34;&#34;&#34;
    Fit AOI averages

    Arguments
    ---------
    sig : np array, 3D
        Sig measurement array, shape: [y, x, sweep_arr]. CROPPED etc. already.
    ref : np array, 3D
        Ref measurement array, shape: [y, x, sweep_arr]. CROPPED etc. already.
    sweep_arr : np array, 1D
        Affine parameter list (e.g. tau or freq)
    fit_model : dukit.pl.model.FitModel
        The model we&#39;re fitting to.
    guess_dict : dict
        dict holding guesses for each parameter type, e.g.
        {&#39;pos&#39;: [.., ..], &#39;amp&#39;: [.., ..], ...}
    bounds_dict : dict
        dict holding bound options for each parameter type, e.g.
        {&#34;pos_range&#34;: 5.0, &#34;amp_bounds&#34;: [0.0, 1.0], ...}
    norm : str default=&#34;div&#34;
        Normalisation method

    Optional parameters passed to cpufit
    ------------------------------------
    tolerance : float = 1e-12
        Fit tolerance threshold
    max_iterations : int = 50
        Maximum fit iterations permitted.
    estimator_id : str = &#34;LSE&#34;
        Estimator to use, &#34;LSE&#34; or &#34;MLE&#34; (least squares or maximum likelihood).
        MLE for Poisson, assuming all noise in data is purely Poissonian.

    Returns
    -------
    fit_image_results : dukit.share.RoiAvgFit
    &#34;&#34;&#34;
    pguess, pbounds = _gen_cf_guesses_bounds(
        fit_model, *dukit.pl.common.gen_init_guesses(fit_model, guess_dict, bounds_dict)
    )

    if norm == &#34;div&#34;:
        sig_norm = sig / ref
    elif norm == &#34;sub&#34;:
        sig_norm = 1 + (sig - ref) / (sig + ref)
    elif norm == &#34;true_sub&#34;:
        sig_norm = (sig - ref) / np.nanmax(sig - ref).reshape(
                sig.shape[:-1] + (1,)
            ),

    avg_sig_norm = np.nanmean(sig_norm, axis=(0, 1))
    avg_sig = np.nanmean(sig, axis=(0, 1))
    avg_ref = np.nanmean(ref, axis=(0, 1))

    # only fit the params we want to :)
    params_to_fit = _get_params_to_fit(fit_model)

    # need to repeat avg_sig_norm twice, as cpufit expects 2D array
    roi_norm_twice = np.repeat([avg_sig_norm], repeats=2, axis=0).astype(np.float32)
    guess = np.repeat([pguess], repeats=2, axis=0).astype(dtype=np.float32)
    constraints = np.repeat([pbounds], repeats=2, axis=0).astype(dtype=np.float32)
    constraint_types = np.array(
        [cf.ConstraintType.LOWER_UPPER for i in range(len(params_to_fit))]
    ).astype(np.int32)

    model_id = _get_cpufit_modelID(fit_model)

    estimator_id = {&#34;LSE&#34;: cf.EstimatorID.LSE, &#34;MLE&#34;: cf.EstimatorID.MLE}.get(
        estimator_id, cf.EstimatorID.LSE
    )

    best_params_cf, _, _, _, _ = cf.fit_constrained(
        roi_norm_twice,
        None,
        model_id,
        guess,
        constraints=constraints,
        constraint_types=constraint_types,
        user_info=sweep_arr.astype(dtype=np.float32),
        parameters_to_fit=params_to_fit,
        estimator_id=estimator_id,
        tolerance=tolerance,
        max_number_iterations=max_iterations,
    )

    best_params = best_params_cf[0, :]  # just take first fit

    # manually compute sigmas, using analytic jacobian etc.
    best_sigmas = dukit.pl.common.calc_sigmas(
        fit_model, sweep_arr, avg_sig_norm, best_params
    )
    best_residual = fit_model(best_params, sweep_arr) - avg_sig_norm

    fit_xvec = np.linspace(
        np.min(sweep_arr),
        np.max(sweep_arr),
        10000,
    )
    fit_yvec = fit_model(best_params, fit_xvec)
    fit_yvec_guess = fit_model(pguess, fit_xvec)
    return dukit.share.RoiAvgFit(
        &#34;cpufit&#34;,
        sweep_arr,
        avg_sig_norm,
        avg_sig,
        avg_ref,
        fit_xvec,
        fit_yvec,
        fit_yvec_guess,
        best_params,
        best_sigmas,
        best_residual,
        pguess,
        pbounds,
    )</code></pre>
</details>
</dd>
</dl>
</section>
<section>
</section>
</article>
<nav id="sidebar">
<form>
<input id="lunr-search" name="q" placeholder="ðŸ”Ž Search ..." aria-label="Search"
disabled minlength="2">
</form>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/tingle/0.15.3/tingle.min.css" integrity="sha512-j1u8eUJ4f23xPPxwOrLUPQaCD2dwzNqqmDDcWS4deWsMv2ohLqmXXuP3hU7g8TyzbMSakP/mMqoNBYWj8AEIFg==" crossorigin>
<script src="https://cdnjs.cloudflare.com/ajax/libs/tingle/0.15.3/tingle.min.js" integrity="sha512-plGUER9JkeEWPPqQBE4sdLqBoQug5Ap+BCGMc7bJ8BXkm+VVj6QzkpBz5Yv2yPkkq+cqg9IpkBaGCas6uDbW8g==" crossorigin></script>
<style>
.modal-dialog iframe {
width: 100vw;
height: calc(100vh - 80px);
}
@media screen and (min-width: 700px) {
.modal-dialog iframe {
width: 70vw;
height: 80vh;
}
}
.modal-dialog .tingle-modal-box {width: auto;}
.modal-dialog .tingle-modal-box__content {padding: 0;}
</style>
<script>
const input = document.getElementById('lunr-search');
input.disabled = false;
input.form.addEventListener('submit', (ev) => {
ev.preventDefault();
const url = new URL(window.location);
url.searchParams.set('q', input.value);
history.replaceState({}, null, url.toString());
search(input.value);
});
const query = new URL(window.location).searchParams.get('q');
if (query)
search(query);
function search(query) {
const url = '../../doc-search.html#' + encodeURIComponent(query);
new tingle.modal({
cssClass: ['modal-dialog'],
onClose: () => {
const url = new URL(window.location);
url.searchParams.delete('q');
history.replaceState({}, null, url.toString());
setTimeout(() => input.focus(), 100);
}
}).setContent('<iframe src="' + url + '"></iframe>').open();
}
</script>
<h1>Index</h1>
<div class="toc">
<ul>
<li><a href="#functions">Functions</a></li>
</ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="dukit.pl" href="index.html">dukit.pl</a></code></li>
</ul>
</li>
<li><h3><a href="#header-functions">Functions</a></h3>
<ul class="">
<li><code><a title="dukit.pl.cpufit._gen_cf_guesses_bounds" href="#dukit.pl.cpufit._gen_cf_guesses_bounds">_gen_cf_guesses_bounds</a></code></li>
<li><code><a title="dukit.pl.cpufit.fit_all_pixels_pl" href="#dukit.pl.cpufit.fit_all_pixels_pl">fit_all_pixels_pl</a></code></li>
<li><code><a title="dukit.pl.cpufit.fit_aois_pl" href="#dukit.pl.cpufit.fit_aois_pl">fit_aois_pl</a></code></li>
<li><code><a title="dukit.pl.cpufit.fit_roi_avg_pl" href="#dukit.pl.cpufit.fit_roi_avg_pl">fit_roi_avg_pl</a></code></li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc"><cite>pdoc</cite> 0.9.2</a>.</p>
</footer>
</body>
</html>